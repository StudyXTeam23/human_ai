# ğŸ”§ OpenAI Token é™åˆ¶ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

é”™è¯¯ä¿¡æ¯:
```
OpenAI API request failed with status 400:
"This model's maximum context length is 128000 tokens. 
However, your messages resulted in 265182 tokens. 
Please reduce the length of the messages."
```

**åŸå› **: ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶æˆ–è¾“å…¥çš„æ–‡æœ¬è¶…è¿‡äº† OpenAI API çš„ token é™åˆ¶ã€‚

## âœ… è§£å†³æ–¹æ¡ˆ

### 1. å®‰è£… tiktoken åº“

```bash
pip install tiktoken
```

`tiktoken` æ˜¯ OpenAI å®˜æ–¹çš„ token è®¡æ•°åº“ï¼Œç”¨äºç²¾ç¡®è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡ã€‚

### 2. å®ç° Token è®¡æ•°å’Œæˆªæ–­

åœ¨ `openai_service.py` ä¸­æ·»åŠ äº†ä»¥ä¸‹åŠŸèƒ½:

#### Token é™åˆ¶é…ç½®

```python
class OpenAIService:
    MAX_CONTEXT_TOKENS = 128000  # gpt-4o å’Œ gpt-4o-mini æœ€å¤§ä¸Šä¸‹æ–‡
    MAX_OUTPUT_TOKENS = 4000     # é¢„ç•™ç»™è¾“å‡º
    MAX_INPUT_TOKENS = MAX_CONTEXT_TOKENS - MAX_OUTPUT_TOKENS - 1000  # é¢„ç•™ç»™ prompt
    # å®é™…è¾“å…¥é™åˆ¶: 123000 tokens
```

#### æ ¸å¿ƒæ–¹æ³•

**1. `_count_tokens(text: str) -> int`**
- ä½¿ç”¨ tiktoken ç²¾ç¡®è®¡ç®—æ–‡æœ¬çš„ token æ•°é‡
- æœ‰ fallback æœºåˆ¶: å¦‚æœè®¡æ•°å¤±è´¥ï¼Œä½¿ç”¨å­—ç¬¦æ•°ä¼°ç®—

**2. `_truncate_text(text: str, max_tokens: int) -> tuple[str, bool]`**
- æˆªæ–­è¶…é•¿æ–‡æœ¬åˆ°æŒ‡å®š token æ•°é‡
- è¿”å› (æˆªæ–­åçš„æ–‡æœ¬, æ˜¯å¦è¢«æˆªæ–­)
- ä¿è¯æˆªæ–­åœ¨ token è¾¹ç•Œä¸Šï¼Œä¸ä¼šç ´åæ–‡æœ¬ç»“æ„

**3. `humanize()` æ–¹æ³•å¢å¼º**
- å¤„ç†å‰å…ˆæ£€æŸ¥ token æ•°é‡
- å¦‚æœè¶…è¿‡é™åˆ¶ï¼Œè‡ªåŠ¨æˆªæ–­
- è®°å½•è¯¦ç»†æ—¥å¿—
- åœ¨è¿”å›ç»“æœä¸­æ·»åŠ æˆªæ–­æç¤º

### 3. å·¥ä½œæµç¨‹

```
ç”¨æˆ·è¾“å…¥æ–‡æœ¬
    â†“
è®¡ç®— token æ•°é‡
    â†“
è¶…è¿‡ 123000 tokens? â”€Noâ†’ æ­£å¸¸å¤„ç†
    â†“ Yes
æˆªæ–­åˆ° 123000 tokens
    â†“
å‘é€åˆ° OpenAI API
    â†“
è¿”å›ç»“æœ + æˆªæ–­æç¤º
```

## ğŸ“Š Token é™åˆ¶è¯¦æƒ…

| é¡¹ç›® | Token æ•°é‡ | è¯´æ˜ |
|------|-----------|------|
| æœ€å¤§ä¸Šä¸‹æ–‡ | 128,000 | OpenAI API æ€»é™åˆ¶ |
| è¾“å‡ºé¢„ç•™ | 4,000 | AI ç”Ÿæˆæ–‡æœ¬çš„ç©ºé—´ |
| Prompt é¢„ç•™ | 1,000 | ç³»ç»Ÿ prompt å’ŒæŒ‡ä»¤ |
| **å®é™…è¾“å…¥é™åˆ¶** | **123,000** | ç”¨æˆ·æ–‡æœ¬çš„æœ€å¤§ token æ•° |

## ğŸ§® Token ä¼°ç®—

ä¸åŒè¯­è¨€çš„ token æ¯”ä¾‹:
- **è‹±æ–‡**: 1 token â‰ˆ 4 å­—ç¬¦ (ä¾‹: "hello world" â‰ˆ 3 tokens)
- **ä¸­æ–‡**: 1 token â‰ˆ 1-2 å­—ç¬¦ (ä¾‹: "ä½ å¥½ä¸–ç•Œ" â‰ˆ 4 tokens)
- **ä»£ç **: 1 token â‰ˆ 4 å­—ç¬¦

å¤§çº¦é™åˆ¶:
- è‹±æ–‡: ~492,000 å­—ç¬¦ (123000 * 4)
- ä¸­æ–‡: ~184,500 å­—ç¬¦ (123000 * 1.5)

## ğŸ“ ä»£ç ç¤ºä¾‹

### ä½¿ç”¨ç¤ºä¾‹

```python
# åœ¨ humanize æ–¹æ³•ä¸­è‡ªåŠ¨å¤„ç†
result = await openai_service.humanize(
    text=long_text,  # å³ä½¿è¶…é•¿ä¹Ÿä¼šè‡ªåŠ¨æˆªæ–­
    length="Normal",
    similarity="Moderate",
    style="Friendly"
)

# æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
if result.get("wasTruncated"):
    original_tokens = result.get("originalTokens")
    print(f"æ–‡æœ¬ä» {original_tokens} tokens è¢«æˆªæ–­åˆ° 123000 tokens")
```

### æ—¥å¿—è¾“å‡º

```
INFO: Input text tokens: 265182
WARNING: Text was truncated to 123000 tokens (original: 265182 tokens)
INFO: Total prompt tokens: 123500
```

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

### 1. è‡ªåŠ¨æˆªæ–­
- âœ… è¶…é•¿æ–‡æœ¬è‡ªåŠ¨æˆªæ–­
- âœ… ä¿è¯ä¸è¶…è¿‡ token é™åˆ¶
- âœ… åœ¨ token è¾¹ç•Œæˆªæ–­ï¼Œä¸ç ´åæ–‡æœ¬

### 2. ç”¨æˆ·æç¤º
- âœ… åœ¨ç»“æœæœ«å°¾æ·»åŠ æˆªæ–­æç¤º
- âœ… æ˜¾ç¤ºåŸå§‹å’Œæˆªæ–­åçš„ token æ•°é‡
- âœ… ç”¨æˆ·å¯ä»¥çœ‹åˆ°æ–‡æœ¬è¢«æˆªæ–­äº†

### 3. è¯¦ç»†æ—¥å¿—
- âœ… è®°å½•è¾“å…¥ token æ•°é‡
- âœ… è®°å½•æ˜¯å¦æˆªæ–­åŠæˆªæ–­æ¯”ä¾‹
- âœ… ä¾¿äºè°ƒè¯•å’Œç›‘æ§

### 4. å®¹é”™å¤„ç†
- âœ… Fallback æœºåˆ¶: tiktoken å¤±è´¥æ—¶ä½¿ç”¨å­—ç¬¦ä¼°ç®—
- âœ… ä¸ä¼šå› ä¸º token è®¡æ•°å¤±è´¥è€Œä¸­æ–­æœåŠ¡

## ğŸ§ª æµ‹è¯•

### æµ‹è¯•æˆªæ–­åŠŸèƒ½

```python
# åˆ›å»ºè¶…é•¿æ–‡æœ¬
long_text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ã€‚" * 100000  # çº¦ 600,000 å­—ç¬¦

# è°ƒç”¨ API
response = await openai_service.humanize(
    text=long_text,
    length="Normal",
    similarity="Moderate",
    style="Friendly"
)

# æ£€æŸ¥ç»“æœ
print(f"å¤„ç†æˆåŠŸ: {len(response['content'])} å­—ç¬¦")
print(f"æ˜¯å¦æˆªæ–­: {response.get('wasTruncated', False)}")
```

## ğŸ“¦ ä¾èµ–æ›´æ–°

å·²æ›´æ–°ä»¥ä¸‹æ–‡ä»¶:
- âœ… `requirements.txt` - æ·»åŠ  tiktoken>=0.5.2
- âœ… `requirements-prod.txt` - æ·»åŠ  tiktoken>=0.5.2

## ğŸš€ éƒ¨ç½²

### å¼€å‘ç¯å¢ƒ

```bash
cd /Users/yuyuan/studyx_human/web/backend
source venv/bin/activate
pip install tiktoken
# é‡å¯åç«¯æœåŠ¡
```

### ç”Ÿäº§ç¯å¢ƒ

```bash
cd /var/www/studyx_human/web/backend
source venv/bin/activate
pip install -r requirements-prod.txt
# é‡å¯æœåŠ¡
pm2 restart humanizer-api
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¯¹äºç”¨æˆ·

1. **æ–‡æœ¬æ¨¡å¼**: 
   - é™åˆ¶: 5000 å­—ç¬¦ (è¿œå°äº token é™åˆ¶ï¼Œä¸ä¼šè§¦å‘æˆªæ–­)

2. **æ–‡æ¡£æ¨¡å¼**:
   - å¤§æ–‡ä»¶ä¼šè‡ªåŠ¨æˆªæ–­
   - å»ºè®®ä¸Šä¼  < 100 é¡µçš„æ–‡æ¡£
   - å¦‚æœæ–‡æ¡£å¤ªå¤§ï¼Œä¼šæ”¶åˆ°æˆªæ–­æç¤º

### å¯¹äºå¼€å‘è€…

1. **è°ƒæ•´é™åˆ¶**:
   ```python
   # å¦‚æœéœ€è¦æ›´ä¿å®ˆçš„é™åˆ¶
   MAX_INPUT_TOKENS = 50000  # å‡å°‘è¾“å…¥é™åˆ¶
   ```

2. **å‰ç«¯éªŒè¯**:
   - å¯ä»¥åœ¨å‰ç«¯æ·»åŠ æ–‡ä»¶å¤§å°é™åˆ¶
   - è¶…è¿‡ 10MB çš„æ–‡æ¡£å»ºè®®æ‹’ç»ä¸Šä¼ 

3. **åˆ†å—å¤„ç†** (æœªæ¥ä¼˜åŒ–):
   - å¯¹äºè¶…é•¿æ–‡æ¡£ï¼Œå¯ä»¥åˆ†å—å¤„ç†
   - æ¯å—ç‹¬ç«‹è°ƒç”¨ API
   - æœ€ååˆå¹¶ç»“æœ

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **Token ä¸ç­‰äºå­—ç¬¦**
   - ä¸­æ–‡å­—ç¬¦é€šå¸¸éœ€è¦æ›´å¤š token
   - ç‰¹æ®Šç¬¦å·å’Œè¡¨æƒ…ç¬¦å·å¯èƒ½å ç”¨å¤šä¸ª token

2. **æˆªæ–­å¯èƒ½å½±å“å†…å®¹**
   - æ–‡æœ¬ä¼šåœ¨ token è¾¹ç•Œæˆªæ–­
   - å¯èƒ½ä¼šæˆªæ–­å¥å­æˆ–æ®µè½
   - å»ºè®®ç”¨æˆ·ä¸Šä¼ åˆé€‚å¤§å°çš„æ–‡æ¡£

3. **æˆæœ¬è€ƒè™‘**
   - æ›´å¤š token = æ›´é«˜æˆæœ¬
   - 123000 tokens â‰ˆ $0.15 (gpt-4o-mini è¾“å…¥ä»·æ ¼)

## ğŸ“š å‚è€ƒèµ„æ–™

- [OpenAI Token é™åˆ¶æ–‡æ¡£](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)
- [tiktoken GitHub](https://github.com/openai/tiktoken)
- [Token è®¡ç®—å™¨](https://platform.openai.com/tokenizer)

---

**çŠ¶æ€**: âœ… å·²å®ç°å¹¶æµ‹è¯•
**ç‰ˆæœ¬**: 1.0.0
**æ›´æ–°æ—¥æœŸ**: 2024-01-23

